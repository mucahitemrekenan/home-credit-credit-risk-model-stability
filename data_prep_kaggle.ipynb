{
 "cells": [
  {
   "cell_type": "code",
   "id": "a9d4e96cfd39c93c",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T08:56:54.391196Z",
     "start_time": "2024-05-21T08:54:06.490238Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "def column_check(data1, data2):\n",
    "    return set(data1.columns) == set(data1.columns).intersection(data2.columns)\n",
    "\n",
    "\n",
    "def merge_duplicate_group_cols(data):\n",
    "    if 'num_group1_x' in data.columns:\n",
    "        data.loc[:, 'num_group1_x'] = data.loc[:, 'num_group1_x'].fillna(data.loc[:, 'num_group1_y'])\n",
    "        data.drop('num_group1_y', axis=1, inplace=True)\n",
    "        data.rename(columns={'num_group1_x': 'num_group1'}, inplace=True)\n",
    "\n",
    "    if 'num_group2_x' in data.columns:\n",
    "        data.loc[:, 'num_group2_x'] = data.loc[:, 'num_group2_x'].fillna(data.loc[:, 'num_group2_y'])\n",
    "        data.drop('num_group2_y', axis=1, inplace=True)\n",
    "        data.rename(columns={'num_group2_x': 'num_group2'}, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def concat_and_merge(base_data, path_list, base_path, rows, cols_to_merge=None):\n",
    "    data = pd.DataFrame()\n",
    "    for file in path_list:\n",
    "        if cols_to_merge:\n",
    "            # I specify whether read all columns or a given list of columns.\n",
    "            data = pd.concat([data, pd.read_csv(base_path + file, usecols=['case_id'] + cols_to_merge, nrows=rows,\n",
    "                                                low_memory=False)], axis=0)\n",
    "        else:\n",
    "            data = pd.concat([data, pd.read_csv(base_path + file, nrows=rows, low_memory=False)], axis=0)\n",
    "\n",
    "    data.drop_duplicates(subset=['case_id'], keep='first', inplace=True)\n",
    "    base_data = base_data.merge(data, on='case_id', how='left')\n",
    "\n",
    "    return merge_duplicate_group_cols(base_data)\n",
    "\n",
    "\n",
    "def get_file_names(file_names, keyword):\n",
    "    return [x for x in file_names if keyword in x]\n",
    "\n",
    "\n",
    "nrows = None\n",
    "files_path = 'csv_files/train/'\n",
    "\n",
    "files = os.listdir(files_path)\n",
    "\n",
    "base_file = ['train_base.csv']\n",
    "applprev_files = get_file_names(files, 'applprev_1')\n",
    "credit_a1_files = get_file_names(files, 'credit_bureau_a_1')\n",
    "credit_a2_files = get_file_names(files, 'credit_bureau_a_2')\n",
    "credit_b_files = get_file_names(files, 'credit_bureau_b')\n",
    "static0_files = get_file_names(files, 'static_0')\n",
    "rest_of_files = set(files) - set(applprev_files + credit_a1_files + credit_a2_files + credit_b_files +\n",
    "                                 static0_files + base_file)\n",
    "\n",
    "appl_features = [\n",
    " 'inittransactioncode_279L',\n",
    " 'actualdpd_943P',\n",
    " 'pmtnum_8L',\n",
    " 'credamount_590A',\n",
    " 'district_544M',\n",
    " 'annuity_853A',\n",
    " 'cancelreason_3545846M',\n",
    " 'downpmt_134A',\n",
    " 'creationdate_885D',\n",
    " 'status_219L',\n",
    " 'mainoccupationinc_437A',\n",
    " 'rejectreason_755M',\n",
    " 'rejectreasonclient_4145042M',\n",
    " 'education_1138M',\n",
    " 'postype_4733339M',\n",
    " 'credtype_587L',\n",
    " 'firstnonzeroinstldate_307D',\n",
    " 'tenor_203L',\n",
    " 'profession_152M',\n",
    " 'credacc_credlmt_575A',\n",
    " 'isbidproduct_390L']\n",
    "\n",
    "credit_a1_features = [\n",
    " 'dpdmaxdateyear_596T',\n",
    " 'numberofcontrsvalue_358L',\n",
    " 'numberofoverdueinstlmax_1039L',\n",
    " 'classificationofcontr_13M',\n",
    " 'dateofcredend_289D',\n",
    " 'dateofcredstart_739D',\n",
    " 'totaloutstanddebtvalue_668A',\n",
    " 'totaldebtoverduevalue_178A',\n",
    " 'numberofoverdueinstls_725L',\n",
    " 'subjectrole_182M',\n",
    " 'monthlyinstlamount_332A',\n",
    " 'financialinstitution_382M',\n",
    " 'description_351M',\n",
    " 'financialinstitution_591M',\n",
    " 'overdueamountmaxdateyear_2T',\n",
    " 'overdueamount_659A',\n",
    " 'contractst_545M',\n",
    " 'contractst_964M',\n",
    " 'purposeofcred_426M',\n",
    " 'dpdmaxdatemonth_89T',\n",
    " 'totaldebtoverduevalue_718A',\n",
    " 'debtoverdue_47A',\n",
    " 'totaloutstanddebtvalue_39A',\n",
    " 'purposeofcred_874M',\n",
    " 'debtoutstand_525A',\n",
    " 'overdueamountmax2_14A',\n",
    " 'dpdmax_139P',\n",
    " 'numberofcontrsvalue_258L',\n",
    " 'overdueamountmax_155A',\n",
    " 'overdueamountmaxdatemonth_365T',\n",
    " 'subjectrole_93M',\n",
    " 'classificationofcontr_400M',\n",
    " 'lastupdate_1112D']\n",
    "\n",
    "static0_features = [\n",
    " 'annuitynextmonth_57A',\n",
    " 'interestrate_311L',\n",
    " 'inittransactioncode_186L',\n",
    " 'numcontrs3months_479L',\n",
    " 'cntpmts24_3658933L',\n",
    " 'lastrejectcommodtypec_5251769M',\n",
    " 'lastapprcommoditycat_1041M',\n",
    " 'lastapprdate_640D',\n",
    " 'pctinstlsallpaidlate6d_3546844L',\n",
    " 'applications30d_658L',\n",
    " 'numinstpaidearly3d_3546850L',\n",
    " 'posfpd30lastmonth_3976960P',\n",
    " 'mobilephncnt_593L',\n",
    " 'clientscnt_100L',\n",
    " 'lastst_736L',\n",
    " 'mastercontrelectronic_519L',\n",
    " 'maxdebt4_972A',\n",
    " 'currdebtcredtyperange_828A',\n",
    " 'numinstregularpaid_973L',\n",
    " 'applicationscnt_464L',\n",
    " 'numactivecredschannel_414L',\n",
    " 'daysoverduetolerancedd_3976961L',\n",
    " 'maxdpdlast6m_474P',\n",
    " 'firstdatedue_489D',\n",
    " 'lastrejectcommoditycat_161M',\n",
    " 'cntincpaycont9m_3716944L',\n",
    " 'pctinstlsallpaidearl3d_427L',\n",
    " 'disbursementtype_67L',\n",
    " 'lastapprcommoditytypec_5251766M',\n",
    " 'twobodfilling_608L',\n",
    " 'applicationscnt_1086L',\n",
    " 'numincomingpmts_3546848L',\n",
    " 'pctinstlsallpaidlate4d_3546849L',\n",
    " 'maxdpdfrom6mto36m_3546853P',\n",
    " 'clientscnt12m_3712952L',\n",
    " 'clientscnt_1071L',\n",
    " 'mastercontrexist_109L',\n",
    " 'deferredmnthsnum_166L',\n",
    " 'pmtnum_254L',\n",
    " 'eir_270L',\n",
    " 'applicationcnt_361L',\n",
    " 'clientscnt6m_3712949L',\n",
    " 'maxdpdtolerance_374P',\n",
    " 'actualdpdtolerance_344P',\n",
    " 'clientscnt_493L',\n",
    " 'numinstpaidearly5d_1087L',\n",
    " 'downpmt_116A',\n",
    " 'totaldebt_9A',\n",
    " 'currdebt_22A',\n",
    " 'clientscnt_157L',\n",
    " 'pctinstlsallpaidlat10d_839L',\n",
    " 'lastrejectreason_759M',\n",
    " 'maininc_215A',\n",
    " 'clientscnt_533L',\n",
    " 'price_1097A',\n",
    " 'annuity_780A',\n",
    " 'lastactivateddate_801D',\n",
    " 'homephncnt_628L',\n",
    " 'numinstpaidlate1d_3546852L',\n",
    " 'disbursedcredamount_1113A',\n",
    " 'numinstunpaidmax_3546851L',\n",
    " 'posfpd10lastmonth_333P',\n",
    " 'numinstlswithdpd10_728L',\n",
    " 'sumoutstandtotal_3546847A',\n",
    " 'numnotactivated_1143L',\n",
    " 'numactiverelcontr_750L',\n",
    " 'numinstls_657L',\n",
    " 'numinstlsallpaid_934L',\n",
    " 'numactivecreds_622L',\n",
    " 'clientscnt_304L',\n",
    " 'applicationscnt_629L',\n",
    " 'numinstpaidearly_338L',\n",
    " 'paytype_783L',\n",
    " 'previouscontdistrict_112M',\n",
    " 'clientscnt_887L',\n",
    " 'sellerplacecnt_915L',\n",
    " 'lastapplicationdate_877D',\n",
    " 'numinstlswithoutdpd_562L',\n",
    " 'clientscnt_1022L',\n",
    " 'avgdpdtolclosure24_3658938P',\n",
    " 'credtype_322L',\n",
    " 'lastcancelreason_561M',\n",
    " 'opencred_647L',\n",
    " 'clientscnt_257L',\n",
    " 'clientscnt_946L',\n",
    " 'lastrejectreasonclient_4145040M',\n",
    " 'totalsettled_863A',\n",
    " 'paytype1st_925L',\n",
    " 'sellerplacescnt_216L',\n",
    " 'clientscnt_360L',\n",
    " 'monthsannuity_845L',\n",
    " 'maxannuity_159A',\n",
    " 'maxdpdlast12m_727P',\n",
    " 'posfstqpd30lastmonth_3976962P',\n",
    " 'isbidproduct_1095L',\n",
    " 'clientscnt_1130L',\n",
    " 'applicationscnt_867L',\n",
    " 'numinsttopaygr_769L',\n",
    " 'commnoinclast6m_3546845L',\n",
    " 'maxdpdlast24m_143P',\n",
    " 'pctinstlsallpaidlate1d_3546856L',\n",
    " 'lastapprcredamount_781A',\n",
    " 'numpmtchanneldd_318L',\n",
    " 'numinstlallpaidearly3d_817L',\n",
    " 'credamount_770A',\n",
    " 'maxdpdlast9m_1059P',\n",
    " 'clientscnt3m_3712950L',\n",
    " 'maxdpdlast3m_392P',\n",
    " 'numrejects9m_859L']\n",
    "\n",
    "rest_of_features = [\n",
    " 'conts_role_79M',\n",
    " 'days360_512L',\n",
    " 'contaddr_district_15M',\n",
    " 'birth_259D',\n",
    " 'secondquarter_766L',\n",
    " 'numberofqueries_373L',\n",
    " 'registaddr_zipcode_184M',\n",
    " 'role_1084L',\n",
    " 'days30_165L',\n",
    " 'personindex_1023L',\n",
    " 'incometype_1044T',\n",
    " 'firstquarter_103L',\n",
    " 'dateofbirth_337D',\n",
    " 'empls_employer_name_740M',\n",
    " 'addres_district_368M',\n",
    " 'education_1103M',\n",
    " 'education_88M',\n",
    " 'empls_economicalst_849M',\n",
    " 'fourthquarter_440L',\n",
    " 'mainoccupationinc_384A',\n",
    " 'contaddr_matchlist_1032L',\n",
    " 'contaddr_zipcode_807M',\n",
    " 'days90_310L',\n",
    " 'registaddr_district_1083M',\n",
    " 'empladdr_zipcode_114M',\n",
    " 'type_25L',\n",
    " 'persontype_1072L',\n",
    " 'language1_981M',\n",
    " 'empladdr_district_926M',\n",
    " 'description_5085714M',\n",
    " 'contaddr_smempladdr_334L',\n",
    " 'maritalst_893M',\n",
    " 'days120_123L',\n",
    " 'education_927M',\n",
    " 'safeguarantyflag_411L',\n",
    " 'addres_zip_823M',\n",
    " 'case_id',\n",
    " 'sex_738L',\n",
    " 'persontype_792L',\n",
    " 'thirdquarter_1082L',\n",
    " 'days180_256L',\n",
    " 'maritalst_385M']\n",
    "\n",
    "base = pd.read_csv(files_path + base_file[0], nrows=nrows)\n",
    "base = concat_and_merge(base, applprev_files, files_path, nrows, appl_features)\n",
    "base = concat_and_merge(base, credit_a1_files, files_path, nrows, credit_a1_features)\n",
    "base = concat_and_merge(base, static0_files, files_path, nrows, static0_features)\n",
    "\n",
    "for file in rest_of_files:\n",
    "    data = pd.read_csv(files_path + file, nrows=nrows, low_memory=False)\n",
    "    data.drop_duplicates(subset=['case_id'], keep='first', inplace=True)\n",
    "    base = base.merge(data, on='case_id', how='left')\n",
    "    base = merge_duplicate_group_cols(base)\n",
    "\n",
    "del data\n",
    "\n",
    "all_features = ['case_id', 'target', 'num_group1', 'date_decision'] + appl_features+credit_a1_features+static0_features+rest_of_features\n",
    "\n",
    "base = base.drop(columns=base.columns.difference(all_features))\n",
    "\n",
    "columns_to_fit = base.columns.drop(['case_id', 'target', 'num_group1', 'date_decision']).tolist()\n",
    "\n",
    "object_cols = base[columns_to_fit].select_dtypes(include=['object']).columns\n",
    "object_cols = object_cols.tolist()\n",
    "\n",
    "encoders = dict()\n",
    "for col in object_cols:\n",
    "    le = LabelEncoder()\n",
    "    base[col] = le.fit_transform(base[col])\n",
    "    encoders[col] = le"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:43:01.850825Z",
     "start_time": "2024-05-21T17:43:01.832549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [8000, 10000],\n",
    "    'learning_rate': [0.05],\n",
    "    'scale_pos_weight': [1,5,10,20,30,50],\n",
    "    'max_depth': [-1],\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "results = list()"
   ],
   "id": "2fd67f4a9c5c0537",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T20:11:40.639553Z",
     "start_time": "2024-05-21T17:43:20.975212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for params in tqdm(grid):\n",
    " lgb = LGBMClassifier(**params)\n",
    " lgb.fit(base[columns_to_fit], base['target'], categorical_feature=object_cols)\n",
    " tn, fp, fn, tp = confusion_matrix(base['target'], lgb.predict(base[columns_to_fit])).ravel()\n",
    " results.append({\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'scale_pos_weight': params['scale_pos_weight'],\n",
    "        'max_depth': params['max_depth'],\n",
    "        'importances': lgb.feature_importances_,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    })\n",
    " \n",
    "results_df = pd.DataFrame(results)"
   ],
   "id": "b0a70846ebe1c9d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "  8%|▊         | 1/12 [11:49<2:10:05, 709.62s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 17%|█▋        | 2/12 [22:13<1:49:54, 659.45s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 25%|██▌       | 3/12 [32:22<1:35:24, 636.10s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 33%|███▎      | 4/12 [42:17<1:22:40, 620.11s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 42%|████▏     | 5/12 [53:39<1:14:55, 642.26s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 50%|█████     | 6/12 [1:06:07<1:07:48, 678.14s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 58%|█████▊    | 7/12 [1:19:25<59:47, 717.59s/it]  C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 67%|██████▋   | 8/12 [1:32:34<49:20, 740.17s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 75%|███████▌  | 9/12 [1:47:12<39:09, 783.17s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 83%|████████▎ | 10/12 [1:59:52<25:52, 776.14s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      " 92%|█████████▏| 11/12 [2:14:22<13:24, 804.92s/it]C:\\Users\\mek\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "100%|██████████| 12/12 [2:28:19<00:00, 741.64s/it]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": "results_df.to_excel('lgb_results.xlsx', index=False)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T20:41:48.884085Z",
     "start_time": "2024-05-21T20:41:48.572246Z"
    }
   },
   "id": "e5157ceb9f88e721",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "#==============================================\n",
    "# test\n",
    "#==============================================\n",
    "\n",
    "nrows = None\n",
    "files_path = 'csv_files/test/'\n",
    "\n",
    "files = os.listdir(files_path)\n",
    "\n",
    "base_file = ['test_base.csv']\n",
    "applprev_files = get_file_names(files, 'applprev_1')\n",
    "credit_a1_files = get_file_names(files, 'credit_bureau_a_1')\n",
    "credit_a2_files = get_file_names(files, 'credit_bureau_a_2')\n",
    "credit_b_files = get_file_names(files, 'credit_bureau_b')\n",
    "static0_files = get_file_names(files, 'static_0')\n",
    "rest_of_files = set(files) - set(applprev_files + credit_a1_files + credit_a2_files + credit_b_files +\n",
    "                                 static0_files + base_file)\n",
    "\n",
    "base = pd.read_csv(files_path + base_file[0], nrows=nrows)\n",
    "base = concat_and_merge(base, applprev_files, files_path, nrows, appl_features)\n",
    "base = concat_and_merge(base, credit_a1_files, files_path, nrows, credit_a1_features)\n",
    "base = concat_and_merge(base, static0_files, files_path, nrows, static0_features)\n",
    "\n",
    "for file in rest_of_files:\n",
    "    data = pd.read_csv(files_path + file, nrows=nrows, low_memory=False)\n",
    "    data.drop_duplicates(subset=['case_id'], keep='first', inplace=True)\n",
    "    base = base.merge(data, on='case_id', how='left')\n",
    "    base = merge_duplicate_group_cols(base)\n",
    "\n",
    "del data\n",
    "\n",
    "base = base.drop(columns=base.columns.difference(all_features))\n",
    "\n",
    "for col in object_cols:\n",
    "    base[col] = base[col].map(lambda s: 'unknown' if s not in encoders[col].classes_ else s)\n",
    "    encoders[col].classes_ = np.append(encoders[col].classes_, 'unknown')  # Add 'unknown' to classes\n",
    "    base[col] = encoders[col].transform(base[col])\n",
    "\n",
    "submission = base[['case_id']]\n",
    "submission.loc[:, 'score'] = lgb.predict_proba(base[columns_to_fit])[:, 1]\n",
    "submission = submission.set_index('case_id')\n",
    "submission.to_csv('./submission.csv')"
   ],
   "id": "64b223db6a142f84",
   "outputs": null,
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
